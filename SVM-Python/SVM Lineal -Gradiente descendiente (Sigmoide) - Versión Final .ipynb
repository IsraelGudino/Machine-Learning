{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from math import floor\n",
    "from math import exp\n",
    "import pandas as pd #Importar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clase para dividir el dataset en Entrenamiento y Testeo\n",
    "def cross_val_split(data_X,data_Y,test_size,seed_val):\n",
    "    data_x = data_X.tolist()\n",
    "    data_y = data_Y.tolist()\n",
    "    seed(seed_val)\n",
    "    train_size = floor((1 - test_size)*len(data_x))\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    while(len(train_x)<train_size):\n",
    "        index = randrange(len(data_x))\n",
    "        train_x.append(data_x.pop(index))\n",
    "        train_y.append(data_y.pop(index))\n",
    "    return train_x,train_y,data_x,data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para devolver las estadísticas de minimos y máximos de la columna para el escalado\n",
    "def statistics(x):\n",
    "    cols = list(zip(*x))\n",
    "    stats = []\n",
    "    for e in cols:\n",
    "        stats.append([min(e),max(e)])\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para escalar las características\n",
    "def scale(x, stat):\n",
    "    for row in x:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - stat[i][0])/(stat[i][1] - stat[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para convertir diferentes clases en diferentes columnas(Separar clases) \n",
    "def one_vs_all_cols(s):\n",
    "    m = list(set(s))\n",
    "    m.sort() #Ordenamos los datos\n",
    "    for i in range(len(s)):\n",
    "        new = [0]*len(m)\n",
    "        new[m.index(s[i])] = 1\n",
    "        s[i] = new\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para calcular \"Theta transpose\"\n",
    "def ThetaTX(Q,X):\n",
    "    det = 0.0\n",
    "    for i in range(len(Q)):\n",
    "        det += X[i]*Q[i]\n",
    "    return det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para calcular el costo por clase negativa (classs = 0)\n",
    "def LinearSVM_cost0(z):\n",
    "    if(z < -1): #Margen\n",
    "        return 0\n",
    "    return z + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para calcular el costo por clase positiva (classs = 1)\n",
    "def LinearSVM_cost1(z):\n",
    "    if(z > 1): #Margen\n",
    "        return 0\n",
    "    return -z + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función pra calcular la Sigmoide\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para calcular el costo de  SVM\n",
    "def cost(theta,c,x,y):\n",
    "    cost = 0.0\n",
    "    for i in range(len(x)):\n",
    "        z = ThetaTX(theta[c], x[i])\n",
    "        cost += y[i]*LinearSVM_cost1(z) + (1 - y[i])*LinearSVM_cost0(z)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para realizar el descenso del gradiente en los pesos / parámetros \n",
    "#(Esto es escencial cuando se usa la función sigmoide para entrenar un SVM,  ya que permite \n",
    "#encontrar los valores mínimos de esta función)\n",
    "def gradDescent(theta,c,x,y,learning_rate):\n",
    "    oldTheta = theta[c]\n",
    "    for Q in range(len(theta[c])):\n",
    "        derivative_sum = 0 \n",
    "        for i in range(len(x)):\n",
    "            derivative_sum += (sigmoid(ThetaTX(oldTheta,x[i])) - y[i])*x[i][Q]\n",
    "        theta[c][Q] -= learning_rate*derivative_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para devolver las predicciones\n",
    "def predict(data,theta):\n",
    "    predictions = []\n",
    "    count = 1\n",
    "    for row in data:\n",
    "        hypothesis = []\n",
    "        multiclass_ans = [0]*len(theta)\n",
    "        for c in range(len(theta)):\n",
    "            z = ThetaTX(row,theta[c])\n",
    "            hypothesis.append(sigmoid(z))\n",
    "        index = hypothesis.index(max(hypothesis))\n",
    "        multiclass_ans[index] = 1\n",
    "        predictions.append(multiclass_ans)\n",
    "        count+=1\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para devolver la predicción y calcular el porcentaje de predicción\n",
    "def accuracy(predicted, actual):\n",
    "    n = len(predicted)\n",
    "    correct = 0\n",
    "    for i in range(n):\n",
    "        if(predicted[i]==actual[i]):\n",
    "            correct+=1\n",
    "    return correct/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para realizar validación cruzada\n",
    "#Aqui calculamos la media arirmética de cada clase para poder evaluar y garantizar que los datos \n",
    "#obtenidos son independientes de los datos de entrenamiento y prueba\n",
    "def cross_validation(x,y,test_data_size,validations,learning_rate,epoch):\n",
    "    accuracies = []\n",
    "    for valid in range(validations):\n",
    "        x_train, y_train, x_test, y_test = cross_val_split(x,y,test_data_size,valid+1)\n",
    "        #Convertir y_train a columnas con valores 0/1\n",
    "        classes = []\n",
    "        for i in range(len(label_map)):\n",
    "            classes.append([row[i] for row in y_train])\n",
    "        #Inicializando función Theta (Pesos)\n",
    "        theta = [[0]*len(x_train[0]) for _ in range(len(classes))]\n",
    "        \n",
    "        #Modelo de entrenamiento\n",
    "        for i in range(epoch):\n",
    "            for class_type in range(len(classes)):\n",
    "                gradDescent(theta,class_type,x_train,classes[class_type],learning_rate)\n",
    "            if(i%(epoch/10)==0):\n",
    "                print(\"Procesando\", i*100/epoch,\"%\")\n",
    "        print(\"Completado\")\n",
    "        \n",
    "        #Predicción usando datos de prueba \n",
    "        y_pred = predict(x_test,theta)\n",
    "        \n",
    "        #Cálculo de al presición\n",
    "        accuracies.append(accuracy(y_pred,y_test))\n",
    "    return sum(accuracies)/len(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Lineal- Función Sigmoide\n",
      "Procesando 0.0 %\n",
      "Procesando 10.0 %\n",
      "Procesando 20.0 %\n",
      "Procesando 30.0 %\n",
      "Procesando 40.0 %\n",
      "Procesando 50.0 %\n",
      "Procesando 60.0 %\n",
      "Procesando 70.0 %\n",
      "Procesando 80.0 %\n",
      "Procesando 90.0 %\n",
      "Completado\n",
      "Datos:  522\n",
      "Tamaño datos de Entrenamiento:  417\n",
      "Tamaño datos de Prueba:  105\n",
      "Porcentaje de aciertos:  84.76190476190476 %\n"
     ]
    }
   ],
   "source": [
    "#Importar Dataset\n",
    "print(\"SVM Lineal- Función Sigmoide\")\n",
    "dataset = pd.read_csv(\"dataset1.csv\")#Importamos dataset\n",
    "data = dataset.values\n",
    "\n",
    "#Separamos a las clases de la etiqueta\n",
    "x = data[:,:(data.shape[1]-2)]\n",
    "y = data[:,(data.shape[1]-1)]\n",
    "#Aqui separamos las carácticas más notorias en mínimos y máximos \n",
    "stats = statistics(x)\n",
    "scale(x,stats)\n",
    "\n",
    "#Convertimos las etiquetas a columnas\n",
    "#Usamos esta función para recuperar la etiqueta original (String)\n",
    "label_map = one_vs_all_cols(y)\n",
    "\n",
    "#Separamos el dataset de Datos de entrenamiento y datos de prueba\n",
    "test_data_size = 0.2\n",
    "learning_rate = 0.01\n",
    "\n",
    "epoch = 20 #Tiempo (ms) para evaluar (Mientas más tiempo- aumenta el porcentaje de aciertos)\n",
    "validations = 1 #Número de validaciones \n",
    "final_score = cross_validation(x,y,test_data_size,validations,learning_rate,epoch)\n",
    "#Resultados\n",
    "print(\"Datos: \", (floor(len(x)*(1 - test_data_size)))+(len(x) - floor(len(x)*(1 - test_data_size))))\n",
    "print(\"Tamaño datos de Entrenamiento: \", floor(len(x)*(1 - test_data_size)))\n",
    "print(\"Tamaño datos de Prueba: \", len(x) - floor(len(x)*(1 - test_data_size)))\n",
    "print(\"Porcentaje de aciertos: \",final_score*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
